<!DOCTYPE html>
<!-- <script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script> -->
<link rel="stylesheet" href="./resources/js/simpleLightbox.min.css">
<script src="./resources/js/simpleLightbox.min.js"></script>
<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	* {box-sizing: border-box;}

	.img-magnifier-container {
	position: relative;
	}

	.img-magnifier-glass {
	position: absolute;
	border: 3px solid #000;
	border-radius: 50%;
	cursor: none;
	/*Set the size of the magnifier glass:*/
	width: 300px;
	height: 300px;
	}
</style>

<html>
<head>
	<title>Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization</title>
	<meta property="og:image" content="resources/teaser.png"/>
	<meta property="og:title" content="Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization" />
	<meta property="og:description" content="Adapting LLMs for the task of summarizing clinical text." />
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());
	  gtag('config', 'G-SM533FK505');
	</script>
	<script>
		/* https://github.com/dbrekalo/simpleLightbox */
		function createLigthboxGallery() {
			new SimpleLightbox({elements: '.ImageGallery a'})
		}
	</script>
</head>

<body onload="createLigthboxGallery();">
	<br>
	<center>
		<span style="font-size:36px">
            Adapted Large Language Models Can Outperform <br /> Medical Experts in Clinical Text Summarization 
		</span>
		</br></br>
		
		<table align=center width=600px>
			<table align=center width=600px>				
				
                <tr style="font-size: 14px", style="padding: 30px 0;">
					<td align=center width=120px >
						<center>
						<span><a href="https://davevanveen.com/">Dave<br />Van Veen</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://caravanuden.com/">Cara<br />Van Uden</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://www.linkedin.com/in/louis-blankemeier/">Louis<br />Blankemeier</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://jbdel.github.io">Jean-Benoit<br />Delbrouck</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://www.linkedin.com/in/asadaali/">Asad<br />Aali</a></span>
						</center>
					</td>
				</tr>
			
                <tr style="font-size: 14px">
					<td align=center width=120px >
						<center>
						<span><a href="https://www.linkedin.com/in/bluethgen/">Christian<br />Bluethgen</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://www.linkedin.com/in/anujpareek-md/?originalSubdomain=dk">Anuj<br />Pareek</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://stanford.edu/">Malgorzata<br />Polacin</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://www.linkedin.com/in/edreismd/">Eduardo P.<br />Reis</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/anna-seehofnerova">Anna<br />Seehofnerova</a></span>
						</center>
					</td>
				</tr>
				
				<tr style="font-size: 14px">
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/nidhi-rohatgi">Nidhi<br />Rohatgi</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/poonam-hosamani">Poonam<br />Hosamani</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/william-collins">William<br />Collins</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/neera-ahuja">Neera<br />Ahuja</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/curtis-langlotz">Curtis P.<br />Langlotz</a></span>
						</center>
					</td>
				</tr>

				<tr style="font-size: 14px">
					<td align=center width=120px >
						<center>
						<span><a href="https://profiles.stanford.edu/jason-hom">Jason<br />Hom</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://med.stanford.edu/profiles/sergios-gatidis">Sergios<br />Gatidis</a></span>
						</center>
					</td>
					<td align=center width=120px >
						<center>
						<span><a href="https://web.stanford.edu/~pauly/">John<br />Pauly</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span><a href="https://profiles.stanford.edu/akshay-chaudhari">Akshay S.<br />Chaudhari</a></span>
						</center>
					</td>
				</tr>

			</table>
		<p style="font-size: 14px">
		<span style="text-align: center;">Stanford University</span>
		</br></p>
		</br></br></br>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:800px; border: 0px;" src="resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
		<br>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://arxiv.org/abs/2309.07430'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='resources/bibtex.txt'>[BibTeX]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/StanfordMIMI/clin-summ'>[Code]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>

		<table align=center width=850px>
			<tr>
				<td>
					
				</td>
			</tr>
		</table>
	</center>

    <br>
	<hr>
    <br>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td style='text-align: justify;'>
                <p>Analyzing vast textual data and summarizing key information from electronic health records imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown promise in natural language processing (NLP), their effectiveness on a diverse range of clinical summarization tasks remains unproven.</p>
                <p>In this study, we apply adaptation methods to eight LLMs, spanning four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP metrics reveal trade-offs between models and adaptation methods. A clinical reader study with ten physicians evaluates summary completeness, correctness, and conciseness; in a majority of cases, summaries from our best adapted LLMs are either equivalent (45%) or superior (36%) compared to summaries from medical experts. The ensuing safety analysis highlights challenges faced by both LLMs and medical experts, as we connect errors to potential medical harm and categorize types of fabricated
information.</p> 
            <p>Our research provides evidence of LLMs outperforming medical experts in clinical text summarization across multiple tasks. This suggests that integrating LLMs into clinical workflows could alleviate documentation burden, allowing clinicians to focus more on patient care.</p>
			</td>
		</tr>
	</table>
	<br>
    
	<br>
    <hr>
    <br>

	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:600px" src="resources/prompt_anatomy.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
				<b>Left:</b> Prompt anatomy for both adaptation methods: in-context learning (ICL, m &gt; 0) and quantized low-rank adaptation (QLoRA, m &equals; 0).
                <b>Right:</b> We generally find better performance when (1) using lower temperature, i.e. generating less random output, as summarization tasks benefit more from truthfulness than creativity (2) assigning the model clinical expertise in the prompt.
			</td>
		</tr>
	</table>
	<br>


    <br>
    <hr>
    <br>

	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:800px" src="resources/win_matrix.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
                    <b>Model win rate</b>: a head-to-head winning percentage of each model combination, where red/blue intensities highlight the degree to which models on the vertical axis outperform models on the horizontal axis. GPT-4 generally achieves the best performance. While FLAN-T5 is more competitive for syntactic metrics such as BLEU, we note this model is constrained to shorter context lengths (see Table 1). When aggregated across datasets, seq2seq models (FLAN-T5, FLAN-UL2) outperform open-source autoregressive models (Llama-2, Vicuna) on all metrics.
			</td>
		</tr>
	</table>
	<br>


    <br>
    <hr>
    <br>

	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:800px" src="resources/graphs_medcon.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
					<b>MEDCON scores vs. number of in-context examples</b> across models and datasets. We also include the best model fine-tuned with QLoRA (FLAN-T5) as a horizontal dashed line for valid datasets. Zero-shot prompting (0 examples) often yields considerably inferior results, underscoring the need for adaptation methods. Note the allowable number of in-context examples varies signficantly by model context length and dataset size. See the paper for results across other metrics.
			</td>
		</tr>
	</table>
	<br>


    <br>
    <hr>
    <br>

	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:600px" src="resources/reader_study.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
					<b>Clinical reader study.</b>
                    <b>(a)</b> Study design comparing the summaries from the best model versus that of medical
experts on three attributes: completeness, correctness, and conciseness.
                    <b>(b)</b> Results. Model summaries are rated higher on all attributes. Highlight colors correspond to a value’s location on the color spectrum. Asterisks (*) denote statistical significance.
                    <b>(c)</b> Distribution of reader scores. Horizontal axes denote reader preference as measured by a five-point Likert scale. Vertical axes denote frequency count, with 1,500 total reports for each plot.
                    <b>(d)</b> Extent and likelihood of potential medical harm caused by choosing summaries from the medical expert (pink) or best model (purple) over the other. Model summaries are preferred in both categories.
                    <b>(e)</b> Reader study user interface.
			</td>
		</tr>
	</table>
	<br>


    <br>
	<hr>
    <br>


	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:800px" src="resources/qual_iii.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
                    <b>Annotation: radiology reports.</b> The table (lower left) contains reader scores for these two examples and the task average across all samples.
                    <b>Top:</b> The model performs better due to a laterality mistake by the medical expert.
                    <b>Bottom:</b> The model exhibits a lack of conciseness. The table (lower left) contains reader scores for these two examples and the task average across all samples.
			</td>
		</tr>
	</table>
	<br>


    <br>
	<hr>
    <br>


	<br>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px >
				<center >
					<td class="img-magnifier-container"><img id="myimage" style="width:400px" src="resources/corr_plot.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=800px>
		<tr>
			<td align=left width=800px>
                    <b>Correlation between NLP metrics and reader scores.</b> The semantic metric (BERTScore) and conceptual metric (MEDCON) correlate most highly with correctness. Meanwhile, syntactic metrics BLEU and ROUGE-L correlate most with completeness.
			</td>
		</tr>
	</table>
	<br>

    <br>
	<hr>
    <br>


	<table align=center width=550px>
		<center><h1>Paper</h1></center>
		<tr>
			<td><a href="https://arxiv.org/abs/2309.07430"><img class="layered-paper-big" style="height:175px" src="resources/thumbnail.png"/></a></td>
			<td><span style="font-size:14pt">D. Van Veen, C. Van Uden, L. Blankemeier,<br />J.B. Delbrouck, A. Aali, C. Bluethgen,<br />A. Pareek, M. Polacin, E.P. Reis<br />A. Seehofnerova, N. Rohatgi, P. Hosamani<br />W. Collins, N. Ahuja, C.P. Langlotz, J. Hom,<br />S. Gatidis, J. Pauly, A.S. Chaudhari<br>
				<b>Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization</b><br>
				2023. (hosted on <a href="https://arxiv.org/pdf/2309.07430.pdf">ArXiv</a>)<br>
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center><a href="resources/bibtex.txt">[Bibtex]</a></center></td>
		</tr>
	</table>

	<br>
	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					<p style="text-align: justify;">
						Microsoft provided Azure OpenAI credits for this project via both the Accelerate Foundation Models Academic Research (AFMAR) program and also a cloud services grant to Stanford Data Science. Further compute support was provided by One Medical, which Asad Aali used as part of his summer internship. Curtis Langlotz is supported by NIH grants R01 HL155410, R01 HL157235, by AHRQ grant R18HS026886, by the Gordon and Betty Moore Foundation, and by the National Institute of Biomedical Imaging and Bioengineering (NIBIB) under contract 75N92020C00021. Akshay Chaudhari receives support from NIH grants R01 HL167974, R01 AR077604, R01 EB002524, R01 AR079431, and P41 EB027060; from NIH contracts 75N92020C00008 and 75N92020C00021; and from GE Healthcare, Philips, and Amazon.
					</p>
				</left>
			</td>
		</tr>
	</table>

<br>
<br>
<hr>

</body>
</html>

